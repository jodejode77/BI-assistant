"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ SQL –∏ —Ç–∏–ø–æ–≤ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
"""

import json
import logging
import time
from pathlib import Path
from typing import Dict, Any, List
import sys

# –î–æ–±–∞–≤–∏—Ç—å —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from tests.test_accuracy import SQLAccuracyTester

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_benchmark(agent, benchmark_path: str, max_tests: int = None):
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–µ
    
    Args:
        agent: –≠–∫–∑–µ–º–ø–ª—è—Ä EnhancedSQLAgent
        benchmark_path: –ü—É—Ç—å –∫ –±–µ–Ω—á–º–∞—Ä–∫—É
        max_tests: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤
    """
    print(f"\nüìã –ó–∞–≥—Ä—É–∑–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞ –∏–∑ {benchmark_path}...")
    
    with open(benchmark_path, 'r', encoding='utf-8') as f:
        benchmark = json.load(f)
    
    if max_tests:
        benchmark = benchmark[:max_tests]
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(benchmark)} —Ç–µ—Å—Ç–æ–≤\n")
    
    tester = SQLAccuracyTester(agent)
    
    results = []
    start_time = time.time()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    viz_stats = {}
    
    for i, test_case in enumerate(benchmark):
        if (i + 1) % 50 == 0:
            print(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {i + 1}/{len(benchmark)} —Ç–µ—Å—Ç–æ–≤...")
        
        result = tester.test_single_query(
            question=test_case['question'],
            expected_sql=test_case['sql'],
            test_id=i + 1
        )
        
        # –î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        result['expected_visualization'] = test_case.get('visualization_type', 'unknown')
        result['source'] = test_case.get('source', 'unknown')
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        viz_type = test_case.get('visualization_type', 'unknown')
        if viz_type not in viz_stats:
            viz_stats[viz_type] = {'total': 0, 'success': 0, 'failed': 0}
        
        viz_stats[viz_type]['total'] += 1
        if result.get('success'):
            viz_stats[viz_type]['success'] += 1
        else:
            viz_stats[viz_type]['failed'] += 1
        
        results.append(result)
    
    total_time = time.time() - start_time
    
    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    total = len(results)
    successful = sum(1 for r in results if r.get('success', False))
    failed = total - successful
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
    successful_results = [r for r in results if r.get('success', False)]
    
    if successful_results:
        exact_matches = sum(
            1 for r in successful_results
            if r.get('comparison', {}).get('exact_match', False)
        )
        
        similarities = [
            r.get('comparison', {}).get('similarity', 0)
            for r in successful_results
            if r.get('comparison')
        ]
        
        tables_matches = sum(
            1 for r in successful_results
            if r.get('comparison', {}).get('tables_match', False)
        )
        
        avg_similarity = sum(similarities) / len(similarities) if similarities else 0
        avg_time = sum(r.get('generation_time', 0) for r in successful_results) / len(successful_results)
        avg_retries = sum(r.get('retry_count', 0) for r in successful_results) / len(successful_results)
        
        confidences = [
            r.get('confidence', 0) for r in successful_results
            if r.get('confidence') is not None
        ]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0
    else:
        exact_matches = 0
        avg_similarity = 0
        tables_matches = 0
        avg_time = 0
        avg_retries = 0
        avg_confidence = 0
    
    stats = {
        'total_tests': total,
        'successful': successful,
        'failed': failed,
        'success_rate': successful / total if total > 0 else 0,
        'exact_matches': exact_matches,
        'exact_match_rate': exact_matches / successful if successful > 0 else 0,
        'avg_similarity': avg_similarity,
        'tables_match_rate': tables_matches / successful if successful > 0 else 0,
        'avg_generation_time': avg_time,
        'avg_retries': avg_retries,
        'avg_confidence': avg_confidence,
        'total_time': total_time,
        'throughput': total / total_time if total_time > 0 else 0,
        'visualization_stats': viz_stats,
        'results': results
    }
    
    return stats


def print_statistics(stats: Dict[str, Any]):
    """–í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    print("\n" + "="*80)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ë–ï–ù–ß–ú–ê–†–ö–ê")
    print("="*80)
    
    print(f"\nüìà –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {stats['total_tests']}")
    print(f"   –£—Å–ø–µ—à–Ω—ã—Ö: {stats['successful']} ({stats['success_rate']*100:.1f}%)")
    print(f"   –ù–µ—É–¥–∞—á–Ω—ã—Ö: {stats['failed']} ({(1-stats['success_rate'])*100:.1f}%)")
    
    print(f"\nüéØ –¢–æ—á–Ω–æ—Å—Ç—å SQL:")
    print(f"   –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {stats['exact_matches']} ({stats['exact_match_rate']*100:.1f}%)")
    print(f"   –°—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å: {stats['avg_similarity']*100:.1f}%")
    print(f"   –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü: {stats['tables_match_rate']*100:.1f}%")
    
    print(f"\n‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {stats['avg_generation_time']:.2f}s")
    print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ retry: {stats['avg_retries']:.2f}")
    print(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {stats['avg_confidence']*100:.1f}%")
    print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {stats['total_time']:.1f}s")
    print(f"   –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å: {stats['throughput']:.2f} –∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫")
    
    if 'visualization_stats' in stats:
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏:")
        for viz_type, viz_stat in sorted(stats['visualization_stats'].items()):
            success_rate = (viz_stat['success'] / viz_stat['total'] * 100) if viz_stat['total'] > 0 else 0
            print(f"   {viz_type}:")
            print(f"      –í—Å–µ–≥–æ: {viz_stat['total']}")
            print(f"      –£—Å–ø–µ—à–Ω—ã—Ö: {viz_stat['success']} ({success_rate:.1f}%)")
            print(f"      –ù–µ—É–¥–∞—á–Ω—ã—Ö: {viz_stat['failed']}")
    
    print("\n" + "="*80)


if __name__ == "__main__":
    from agents.enhanced_sql_agent import create_universal_sql_agent
    from core.llm_manager import LLMManager
    from config.config import settings
    
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ SQL –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–µ\n")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
    print("üì° –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞...")
    try:
        # –ü–æ–ª—É—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        provider_key_map = {
            "gemini": "gemini_api_key",
            "openai": "openai_api_key",
            "anthropic": "anthropic_api_key"
        }
        api_key_name = provider_key_map.get(settings.llm_provider, "gemini_api_key")
        api_key = getattr(settings, api_key_name, None)
        
        llm = LLMManager(
            provider=settings.llm_provider,
            model=settings.llm_model,
            gemini_api_key=api_key if settings.llm_provider == "gemini" else None,
            openai_api_key=api_key if settings.llm_provider == "openai" else None,
            anthropic_api_key=api_key if settings.llm_provider == "anthropic" else None
        )
        
        agent = create_universal_sql_agent(
            connection_url=settings.database_url,
            llm_manager=llm,
            enable_analysis=True,
            max_retries=2
        )
        
        print("‚úÖ –ê–≥–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω\n")
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–µ
        benchmark_path = project_root / "tests" / "benchmark_3000.json"
        
        if not benchmark_path.exists():
            print(f"‚ö†Ô∏è  –ë–µ–Ω—á–º–∞—Ä–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω. –°–æ–∑–¥–∞—é...")
            from tests.create_benchmark import create_benchmark
            
            csv_path = project_root / "home_credit_qa_11000_with_hard_joins.csv"
            json_path = project_root / "result10000.json"
            
            create_benchmark(
                csv_path=str(csv_path),
                json_path=str(json_path),
                output_path=str(benchmark_path),
                target_size=3000
            )
        
        # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–º–æ–∂–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞)
        max_tests = 100  # –î–ª—è –Ω–∞—á–∞–ª–∞ 100, –ø–æ—Ç–æ–º –º–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å
        
        stats = test_benchmark(agent, str(benchmark_path), max_tests=max_tests)
        print_statistics(stats)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results_file = project_root / "tests" / "results" / "benchmark_test_results.json"
        results_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {results_file}")
        print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}", exc_info=True)
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")

